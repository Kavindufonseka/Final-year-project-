from flask import Flask, request, jsonify, render_template
import joblib
import re
from urllib.parse import urlparse
from scipy.sparse import hstack, csr_matrix
import numpy as np

# Define the url_tokenizer function
def url_tokenizer(url):
    return re.split(r'\W+', url)

# Load the model and vectorizer
model = joblib.load('optimized_malware_model.pkl')
vectorizer = joblib.load('optimized_vectorizer.pkl')

# Feature extraction function
def extract_features(url):
    features = {}
    features['length'] = len(url)
    features['num_dots'] = url.count('.')
    features['has_special'] = int(bool(re.search(r'[^a-zA-Z0-9./:]', url)))
    features['domain_length'] = len(urlparse(url).netloc)
    return features

# Flask app
app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    url = request.form['url']

    # Vectorize the URL
    url_vectorized = vectorizer.transform([url])

    # Extract additional features
    features = extract_features(url)
    features_array = np.array([[
        features['length'],
        features['num_dots'],
        features['has_special'],
        features['domain_length']
    ]])
    features_sparse = csr_matrix(features_array)

    # Combine features
    combined_features = hstack([url_vectorized, features_sparse])

    # Make prediction
    prediction = model.predict(combined_features)

    return jsonify({'prediction': prediction[0]})

if __name__ == '__main__':
    app.run(debug=True, port=5001)
