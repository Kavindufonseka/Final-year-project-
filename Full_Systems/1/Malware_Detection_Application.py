#! /usr/bin/python3
import pefile
import os
import array
import math
import pickle
import joblib
from flask import Flask, request, jsonify, render_template, abort, redirect, url_for, session
from werkzeug.utils import secure_filename
from sklearn.ensemble import RandomForestClassifier

def cutit(s, n):
    return s[n:]

app = Flask(__name__)
app.secret_key = 'malware_detection_key'

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/uploader', methods=['GET', 'POST'])
def upload_file():
    if request.method == 'POST':
        scan_type = request.form.get('scan_type', 'file')
        scan_results = []

        if scan_type == 'file':
            f = request.files['file']
            if not f:
                print("No file selected")
                return render_template('index.html', error="No file selected")

            filename = secure_filename(f.filename)
            file_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'uploads', filename)

            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            f.save(file_path)

            print(f"File saved at: {file_path}")
            if not os.path.exists(file_path):
                print(f"File does not exist: {file_path}")
                return render_template('index.html', error="File not found")

            result = analyze_file(file_path)
            if result is not None:
                scan_results.append({
                    'filename': filename,
                    'path': file_path,
                    'status': 'malicious' if result == 0 else 'legitimate'
                })
            else:
                print(f"Analysis failed for file: {file_path}")
        else:
            directory = request.form.get('directory', '')
            if not directory or not os.path.isdir(directory):
                print("Invalid directory")
                return render_template('index.html', error="Invalid directory")

            scan_results = scan_directory(directory)
            if not scan_results:
                print(f"No results from directory scan: {directory}")

        session['scan_results'] = scan_results
        malicious_count = sum(1 for file in scan_results if file['status'] == 'malicious')

        print(f"Scan results: {scan_results}")
        print(f"Malicious count: {malicious_count}")

        return render_template('result.html',
                               scan_results=scan_results,
                               malicious_count=malicious_count,
                               total_files=len(scan_results))

def analyze_file(file_path):
    try:
        with open(file_path, 'rb') as file:
            header = file.read(2)
            if header != b'MZ':
                print(f"File is not a valid PE file: {file_path}")
                return None

        clf = joblib.load(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'classifier/classifier.pkl'))
        features = pickle.loads(open(os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                                 'classifier/features.pkl'), 'rb').read())

        data = extract_infos(file_path)
        if not data:
            print(f"Failed to extract features from file: {file_path}")
            return None

        pe_features = list(map(lambda x: data[x], features))

        res = clf.predict([pe_features])[0]
        print(f"Analysis result for {file_path}: {'malicious' if res == 0 else 'legitimate'}")
        return res
    except Exception as e:
        print(f"Error analyzing file {file_path}: {str(e)}")
        return None

def scan_directory(directory):
    scan_results = []
    clf = joblib.load(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'classifier/classifier.pkl'))
    features = pickle.loads(open(os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                             'classifier/features.pkl'), 'rb').read())

    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                with open(file_path, 'rb') as f:
                    header = f.read(2)
                    if header != b'MZ':
                        continue

                data = extract_infos(file_path)
                if not data:
                    print(f"Failed to extract features from file: {file_path}")
                    continue

                pe_features = list(map(lambda x: data[x], features))
                res = clf.predict([pe_features])[0]

                scan_results.append({
                    'filename': file,
                    'path': file_path,
                    'status': 'malicious' if res == 0 else 'legitimate'
                })
            except Exception as e:
                print(f"Error scanning file {file_path}: {str(e)}")
                continue

    return scan_results

def get_entropy(data):
    if len(data) == 0:
        return 0.0
    occurences = array.array('L', [0] * 256)
    for x in data:
        occurences[x if isinstance(x, int) else ord(x)] += 1

    entropy = 0
    for x in occurences:
        if x:
            p_x = float(x) / len(data)
            entropy -= p_x * math.log(p_x, 2)

    return entropy

def get_resources(pe):
    resources = []
    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):
        try:
            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:
                if hasattr(resource_type, 'directory'):
                    for resource_id in resource_type.directory.entries:
                        if hasattr(resource_id, 'directory'):
                            for resource_lang in resource_id.directory.entries:
                                data = pe.get_data(resource_lang.data.struct.OffsetToData,
                                                   resource_lang.data.struct.Size)
                                size = resource_lang.data.struct.Size
                                entropy = get_entropy(data)

                                resources.append([entropy, size])
        except Exception as e:
            return resources
    return resources

def get_version_info(pe):
    res = {}
    for fileinfo in pe.FileInfo:
        if fileinfo.Key == 'StringFileInfo':
            for st in fileinfo.StringTable:
                for entry in st.entries.items():
                    res[entry[0]] = entry[1]
        if fileinfo.Key == 'VarFileInfo':
            for var in fileinfo.Var:
                res[var.entry.items()[0][0]] = var.entry.items()[0][1]
    if hasattr(pe, 'VS_FIXEDFILEINFO'):
        res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags
        res['os'] = pe.VS_FIXEDFILEINFO.FileOS
        res['type'] = pe.VS_FIXEDFILEINFO.FileType
        res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS
        res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS
        res['signature'] = pe.VS_FIXEDFILEINFO.Signature
        res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion
    return res

def extract_infos(fpath):
    res = {}
    pe = pefile.PE(fpath)
    res['Machine'] = pe.FILE_HEADER.Machine
    res['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader
    res['Characteristics'] = pe.FILE_HEADER.Characteristics
    res['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion
    res['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion
    res['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode
    res['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData
    res['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData
    res['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint
    res['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode
    try:
        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData
    except AttributeError:
        res['BaseOfData'] = 0
    res['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase
    res['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment
    res['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment
    res['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion
    res['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion
    res['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion
    res['MinorImageVersion'] = pe.OPTIONAL_HEADER.MinorImageVersion
    res['MajorSubsystemVersion'] = pe.OPTIONAL_HEADER.MajorSubsystemVersion
    res['MinorSubsystemVersion'] = pe.OPTIONAL_HEADER.MinorSubsystemVersion
    res['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage
    res['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders
    res['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum
    res['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem
    res['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics
    res['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve
    res['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit
    res['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve
    res['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit
    res['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags
    res['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes

    res['SectionsNb'] = len(pe.sections)
    entropy = list(map(lambda x: x.get_entropy(), pe.sections))
    res['SectionsMeanEntropy'] = sum(entropy) / float(len(entropy))
    res['SectionsMinEntropy'] = min(entropy)
    res['SectionsMaxEntropy'] = max(entropy)
    raw_sizes = list(map(lambda x: x.SizeOfRawData, pe.sections))
    res['SectionsMeanRawsize'] = sum(raw_sizes) / float(len(raw_sizes))
    res['SectionsMinRawsize'] = min(raw_sizes)
    res['SectionsMaxRawsize'] = max(raw_sizes)
    virtual_sizes = list(map(lambda x: x.Misc_VirtualSize, pe.sections))
    res['SectionsMeanVirtualsize'] = sum(virtual_sizes) / float(len(virtual_sizes))
    res['SectionsMinVirtualsize'] = min(virtual_sizes)
    res['SectionMaxVirtualsize'] = max(virtual_sizes)

    try:
        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)
        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])
        res['ImportsNb'] = len(imports)
        res['ImportsNbOrdinal'] = len(list(filter(lambda x: x.name is None, imports)))
    except AttributeError:
        res['ImportsNbDLL'] = 0
        res['ImportsNb'] = 0
        res['ImportsNbOrdinal'] = 0

    try:
        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)
    except AttributeError:
        res['ExportNb'] = 0

    resources = get_resources(pe)
    res['ResourcesNb'] = len(resources)
    if len(resources) > 0:
        entropy = list(map(lambda x: x[0], resources))
        res['ResourcesMeanEntropy'] = sum(entropy) / float(len(entropy))
        res['ResourcesMinEntropy'] = min(entropy)
        res['ResourcesMaxEntropy'] = max(entropy)
        sizes = list(map(lambda x: x[1], resources))
        res['ResourcesMeanSize'] = sum(sizes) / float(len(sizes))
        res['ResourcesMinSize'] = min(sizes)
        res['ResourcesMaxSize'] = max(sizes)
    else:
        res['ResourcesNb'] = 0
        res['ResourcesMeanEntropy'] = 0
        res['ResourcesMinEntropy'] = 0
        res['ResourcesMaxEntropy'] = 0
        res['ResourcesMeanSize'] = 0
        res['ResourcesMinSize'] = 0
        res['ResourcesMaxSize'] = 0

    try:
        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size
    except AttributeError:
        res['LoadConfigurationSize'] = 0

    try:
        version_infos = get_version_info(pe)
        res['VersionInformationSize'] = len(version_infos.keys())
    except AttributeError:
        res['VersionInformationSize'] = 0
    return res

if __name__ == '__main__':
    os.makedirs(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'uploads'), exist_ok=True)
    app.run(debug=True)
